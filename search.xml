<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[使用Docker容器化SpringBoot+Dubbo应用的实践]]></title>
    <url>%2F2018%2F06%2F10%2F%E4%BD%BF%E7%94%A8Docker%E5%AE%B9%E5%99%A8%E5%8C%96SpringBoot-Dubbo%E5%BA%94%E7%94%A8%E7%9A%84%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[使用Docker容器化SpringBoot+Dubbo应用的实践Docker在日常开发中越来越火，工作中后端很多项目都需要使用Docker进行容器化，SpringBoot+Docker被称为“原生云应用”，SpringBoot应用和Docker结合非常容易。但是对于Dubbo和Docker结合就不是那么的顺利，由于Dubbo官方停止维护许久，同时Dubbo官方在不久前才开始积极支持SpringBoot。我在踩了很多坑之后，用本篇博客记录使用Docker容器化Dubbo应用的方法，接我的上一篇SpringBoot+Dubbo的博客。 要解决的问题 Dubbo Provider在Docker container中进行服务注册，在zookeeper中的注册IP是容器IP，这样外部的Dubbo Consumer是无法调用的。 开始我们需要准备好一个SpringBoot+Dubbo的项目（我直接使用的我上一篇博客的项目），同时本机需要安装Docker。 新建一个Dockerfile 1vi Dockerfile 编写Dockerfile 123456789FROM openjdk:8-jre-alpineMAINTAINER luoliangADD target/dubbo-provider.jar app.jarENTRYPOINT ["java", "-Djava.security.egd=file:/dev/./urandom", "-jar","/app.jar"]EXPOSE 12345 构建镜像 1docker build -t dubbo-provider . 运行Provider容器 1docker run -d -p 12345:12345 --name dubbo-provider dubbo-provider 查看容器的启动日志 可以看到日志输出的current host: 172.17.0.2，这个IP就是容器内的IP，同时可以看到服务注册的IP也是172.17.0.2，此时我的本地IP是192.168.1.7，如果消费者去消费服务，是不会成功的。 启动消费者会直接报错 这种情况网上很多解决办法都是通过固定容器IP来解决，这样的话移植性不是很好。Dubbo在重新维护后，在新版本中添加了两个环境变量，用于支持Docker容器。可以查看官方的issue. 修改上面的Dockerfile，添加envDUBBO_IP_TO_REGISTRY 填写在zookeeper中注册的IP123456789101112FROM openjdk:8-jre-alpineMAINTAINER luoliangENV DUBBO_IP_TO_REGISTRY 192.168.1.7ENV DUBBO_PORT_TO_REGISTRY 12345ADD target/dubbo-provider.jar app.jarENTRYPOINT [&quot;java&quot;, &quot;-Djava.security.egd=file:/dev/./urandom&quot;, &quot;-jar&quot;,&quot;/app.jar&quot;]EXPOSE 12345 重新build之后重新启动一个容器，可以看到服务注册地址已经变成了指定的IP，消费者可以成功的进行调用。 也可以不修改Dockerfile，通过run命令传入参数 1docker run -d -p 12345:12345 -e DUBBO_IP_TO_REGISTRY=192.168.1.7 -e DUBBO_PORT_TO_REGISTRY=12345 --name dubbo-provider dubbo-provider 此时服务提供者的log如下 这时候虽然current host还是172.17.0.2，但服务的注册地址已经变成了192.168.1.7。 使用maven插件构建镜像上面我们都是通过手动构建的镜像，为了提高效率，同时也能让SpringBoot+Dubbo这样的项目能更好的融入像Jenkins这样的CI系统中，构建出全自动的pipeline。 在pom中加入插件的依赖 1234567891011121314151617181920&lt;plugin&gt; &lt;groupId&gt;com.spotify&lt;/groupId&gt; &lt;artifactId&gt;dockerfile-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;default&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;goal&gt;push&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;repository&gt;dubbo-provider&lt;/repository&gt; &lt;tag&gt;latest&lt;/tag&gt; &lt;buildArgs&gt; &lt;JAR_FILE&gt;$&#123;project.build.finalName&#125;.jar&lt;/JAR_FILE&gt; &lt;/buildArgs&gt; &lt;/configuration&gt;&lt;/plugin&gt; 把dockerfile放在和pom.xml同级的目录下 123project/ Dockerfile pom.xml 使用maven命令进行打包 1mvn package 或者 mvn dockerfile:build 命令执行完成，可以使用docker images查看镜像，剩余步骤同上。经测试，容器运行正常 End本文到这里就结束了，我在上一篇博客的源码中进行了一些改动，文中用到的Dockfile都在其中，源码在这里，文章是个人学习的实践总结，会有不完善的地方，若有更好的做法，欢迎大家指出，谢谢！]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Dubbo</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式-装饰器模式]]></title>
    <url>%2F2018%2F06%2F02%2FJava%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式之装饰器模式 装饰器模式是一种结构型设计模式，可以做到在不改变原来对象功能的情况下，向原有的对象添加新的功能，起到一个装饰的作用。具体的做法是创建一个装饰器类，用来包装原有的类，在不改变原有类方法的情况下，为原有类添加新的功能。 来看一个例子，我们在外面吃饭，有很多食物，其中有烧烤和火锅。比如我们点了烧烤，但是觉得味道不够爽，所以我们选择让老板加盐，或者加辣椒，这里的加盐和加辣椒其实就是对事物起装饰作用。用代码实现如下： 创建Food接口提供两个抽象方法12345678910111213public interface Food &#123; /** * 返回描述 * @return */ String getDesc(); /** * 返回价格 * @return */ String getCost();&#125; 创建实现接口的实现类Barbecue实现类12345678910111213141516171819202122public class BarbecueFood implements Food &#123; /** * 返回描述 * * @return */ @Override public String getDesc() &#123; return "烧烤"; &#125; /** * 返回价格 * * @return */ @Override public String getCost() &#123; Double cost = 3.0; return String.format("最后价格：%s块", cost); &#125;&#125; Hotpot实现类12345678910111213141516171819202122public class HotpotFood implements Food &#123; /** * 返回描述 * * @return */ @Override public String getDesc() &#123; return "火锅"; &#125; /** * 返回价格 * * @return */ @Override public String getCost() &#123; Double cost = 100.0; return String.format("最后价格：%s块", cost); &#125;&#125; 创建装饰器基类FoodDecorator是一个抽象类，其中组合Food类123456789101112131415161718192021222324252627public abstract class FoodDecorator implements Food &#123; protected Food food; public FoodDecorator(Food food) &#123; this.food = food; &#125; /** * 返回描述 * * @return */ @Override public String getDesc() &#123; return food.getDesc(); &#125; /** * 返回价格 * * @return */ @Override public String getCost() &#123; return food.getCost(); &#125;&#125; 创建SaltFoodDecorator装饰器类123456789101112131415161718192021222324252627282930313233public class SaltFoodDecorator extends FoodDecorator &#123; public SaltFoodDecorator(Food food) &#123; super(food); &#125; /** * 返回描述 * * @return */ @Override public String getDesc() &#123; String result = "加盐的" + food.getDesc(); return result; &#125; /** * 返回价格 * * @return */ @Override public String getCost() &#123; Double salt = 2.0; System.out.println(String.format("加盐多收%s块", salt)); String result = food.getCost() + " + " + salt + "块"; return result; &#125;&#125; 创建PepperFoodDecorator装饰器类1234567891011121314151617181920212223242526272829303132public class PepperFoodDecorator extends FoodDecorator &#123; public PepperFoodDecorator(Food food) &#123; super(food); &#125; /** * 返回描述 * * @return */ @Override public String getDesc() &#123; String result = "加盐的" + food.getDesc(); return result; &#125; /** * 返回价格 * * @return */ @Override public String getCost() &#123; Double pepper = 10.0; System.out.println(String.format("加辣椒多收%s块", pepper)); String result = food.getCost() + " + " + pepper + "块"; return result; &#125;&#125; 最后来测试一下1234567891011121314151617181920212223public class Main &#123; public static void main(String[] args) &#123; //创建不用装饰器修饰的Food Food food = new BarbecueFood(); display(food.getDesc()); display(food.getCost()); System.out.println("-------------分割线---------------"); //创建用SaltFoodDecorator装饰的Food Food barbecue = new SaltFoodDecorator(new BarbecueFood()); display(barbecue.getDesc()); display(barbecue.getCost()); System.out.println("-------------分割线---------------"); //创建用PepperFoodDecorator装饰的Food Food hotSpot = new PepperFoodDecorator(new HotpotFood()); display(hotSpot.getDesc()); display(hotSpot.getCost()); &#125; private static void display(Object obj) &#123; System.out.println(obj); &#125;&#125; 结果如下：12345678910烧烤最后价格：3.0块-------------分割线---------------加盐的烧烤加盐多收2.0块最后价格：3.0块 + 2.0块-------------分割线---------------加盐的火锅加辣椒多收10.0块最后价格：100.0块 + 10.0块 来看一下类图会更加地清晰 END装饰器模式在日常开发中也有很多应用，典型的就是JDK里面的IO。InputStream代表输入流，输入来源可以是文件（FileInputStream）、管道（PipedInputStream）、数组（ByteArrayInputStream）等。就像上面的烧烤，火锅。FilterInputStream就是装饰器的基类，他的实现类是一系列的装饰器，比如BufferedInputStream可以用缓冲区来修饰InputStream，把InputSteam包装成有缓冲区的输入流。]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>装饰器模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发之多线程]]></title>
    <url>%2F2018%2F05%2F30%2FJava%E5%B9%B6%E5%8F%91%E4%B9%8B%E5%A4%9A%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Java并发之多线程什么是线程？ 通常我们在使用桌面操作系统的时候，说的都是XXX进程。比如我们启动一个Java程序，那操作系统中就会新建一个Java进程。那线程是什么呢？线程是比进程更加轻量级的调度单位，在现代操作系统中，线程就是最小的调度单位，又被称为“轻量级进程”。 在一个进程中是可以创建多个线程的，这些线程拥有自己的虚拟机栈，本地方法栈，程序计数器。如下图JVM的运行时内存划分中绿色的部分，就是线程私有的。CPU在多个线程中高速切换，让用户感觉像是在同时执行。总结来说，操作系统中可以同时执行多个任务，每个任务就是进程；进程可以同时执行多个任务，每个任务就是线程。 有些初次学习Java的同学可能会很疑惑，好像在日常的开发中，很少用到多线程啊？其实多线程就伴随着我们的日常开发，举个栗子，如果只用单线程，那么在SpringMVC中，前端每发起一个HTTP请求，那么后端接口就会进入阻塞，等待这个线程执行完成，后面的请求才能继续执行。这样的情况下效率将会非常低下。之所以SpringMVC能同时处理多个请求，当然是使用了多线程。 其实Java程序天生就是多线程程序，让我们来看一段简单的Java代码：123456789101112public static void main(String[] args) &#123; //获取Java线程管理的MXBean ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); //仅获取线程和堆栈信息 ThreadInfo[] threadInfos = threadMXBean.dumpAllThreads(false, false); //遍历线程信息，仅打印线程ID和线程名称信息 for (ThreadInfo threadInfo : threadInfos) &#123; System.out.println("[" + threadInfo.getThreadId() + "]" + threadInfo.getThreadName()); &#125; //打印当前线程名字 System.out.println(Thread.currentThread().getName());&#125; 结果如下（不同版本的JDK可能不同）：123456[5]Monitor Ctrl-Break[4]Signal Dispatcher[3]Finalizer[2]Reference Handler[1]mainThreadId:1 ThreadName:main 可以看出，我们仅仅跑了一个main方法，但是却有多个其他线程在同时执行。 为什么使用多线程？ 发挥多处理器核心的优势现在的计算机核心数量已经越来越多，单核的计算机几乎已经不存在了。一个程序可以作为一个进程来运行，程序运行过程中可以创建多个线程，而一个线程在同一时刻只能运行在一个处理器核心上。如果是单线程程序，那么同一时间只能有一个进程的一个线程运行，即时有再多的核心，也无法发挥出多核处理器的优势。如果使用多线程，可以在不同的核心上运行不同的计算逻辑，将会显著的提升性能。 提升响应时间在有一些业务逻辑中，会涉及到复杂的流程，比如创建一个用户，要初始化很多数据，用户信息，用户菜单等等。用户在使用这个功能的时候，如果要等到所有流程执行完才能看到返回成功，那么很多用户是不能忍受这么长时间等待的。这时候就可以利用多线程，异步地去执行某些用户不关心的操作，尽快返回结果，提升用户体验。 合理利用系统资源进程在系统中是相互分隔的，而线程之间隔离程度比进程小，而且线程可以共享内存，进程公有数据，相互之间很容易就能实现通信。同时，创建线程的代价比进程要小很多，而且多线程执行效率也比多进程更高更节省系统资源。 多线程的好处不仅仅是这些，正是因为多线程带来的诸多好多，Java在语言内就内置了多线程支持，Java为多线程提供了良好的变成模型，让开发者能够专注对于问题的解决，为所遇到的问题建立合适的模型，而不是绞尽脑汁去思考如何将程序多线程化。 Java多线程的创建在Java中有三种方式来实现多线程，但是都离不开Thread这个类，所有的线程对象都必须是Thread类或其子类的实例。每个线程都是执行一段程序流，Java使用线程执行体来代表这段程序流。 继承Thread类创建线程步骤如下： 定义一个类继承Thread，并且重写其run()方法，run()方法就是我们所说的线程执行体。 创建Thread子类的实例，就相当于创建了线程对象。 调用实例的start()方法来启动线程。 具体代码如下：1234567891011121314151617181920public class ThreadTest &#123; public static void main(String[] args) throws Exception &#123; for (int i = 0; i &lt; 5; i++) &#123; MyThread thread = new MyThread("MyThread-" + i); thread.start(); &#125; &#125;&#125;class MyThread extends Thread &#123; public MyThread(String name) &#123; super(name); &#125; @Override public void run() &#123; //这里可以直接使用getName()方法获取线程的名称，该方法是Thread类的实例方法 System.out.println(this.getName() + ":created success"); &#125;&#125; 结果如下：12345MyThread-0:created successMyThread-1:created successMyThread-2:created successMyThread-3:created successMyThread-4:created success 实现Runnable接口来创建线程 定义Runnable接口的实现类，并重写该类的run()方法，该run()方法的方法体同样是该线程的线程执行体。 创建Runnable实现类的实例，并且以此实例作为Thread类的target来创建Thread对象，这个Thread对象才是真正的线程对象。 我们可以查看Thread的构造函数123public Thread(Runnable target, String name) &#123; init(null, target, name, 0);&#125; 具体代码如下：123456789101112131415161718public class ThreadTest &#123; public static void main(String[] args) throws Exception &#123; MyThread myThread; for (int i = 0; i &lt; 5; i++) &#123; myThread = new MyThread(); new Thread(myThread, "MyThread-").start(); &#125; &#125;&#125;class MyThread implements Runnable &#123; @Override public void run() &#123; //这里必须使用Thread.currentThread()方法来获取当前线程 System.out.println(Thread.currentThread().getName() + ":created success"); &#125;&#125; 执行结果同上 实现Callable接口创建线程 在上面的两种实现方式，都是在日常开发中经常见到的方式，但是从Java5开始，提供了Callable接口，它提供了一个call()方法来作为线程执行体，但不同的是call()方法比run()方法更加强大。call()方法可以有返回值，同时call()方法可以声明抛出异常。 Callable不能直接作为Thread的target，因为他不是Runnable的子接口，所以Java提供了一个FutureTask实现类，该实现类同时实现了Future接口和Runnable接口，Future接口代表了call()方法的返回值。使用Callable的步骤如下： 创建Callable接口的实现类，实现call()方法，再创建该类的实例。 使用FutureTask来包装Callable对象，FutureTask封装了Callable对象的call()方法的返回值。 使用FutureTask的对象作为Thread对象的target来启动新线程。 调用FutureTask对象的get()方法来实现线程类，并启动新线程。 具体代码如下：123456789101112131415161718192021public class ThreadTest &#123; public static void main(String[] args) throws Exception &#123; FutureTask&lt;Integer&gt; task; for (int i = 0; i &lt; 5; i++) &#123; task = new FutureTask&lt;&gt;(new MyThread()); String name = "MyThread-" + i; new Thread(task, name).start(); System.out.println(name + " return:" + task.get()); &#125; &#125;&#125;class MyThread implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; Integer i = new Random().nextInt(10); System.out.println(Thread.currentThread().getName() + ":created success"); return i; &#125;&#125; 结果如下：12345678910MyThread-0:created successMyThread-0 return:8MyThread-1:created successMyThread-1 return:9MyThread-2:created successMyThread-2 return:1MyThread-3:created successMyThread-3 return:3MyThread-4:created successMyThread-4 return:7 Runnable和Callable在JDK1.8之后已经变成了函数式接口，可以使用lambda表达式来创建他们的对象，会使代码更加的简洁。通过上述三种方式都可以实现多线程，实现Runnable和Callable接口的方式基本上相似，只是Callable的功能更加强大一些。在实际开发中可以根据自己的需求进行选择。 线程的生命周期在知道了怎么创建线程之后，我们还需要搞清楚线程的生命周期。线程需要经历新建（new），就绪（Runnable），运行（Running），阻塞（Blocked）和死亡（Dead）这5种状态。下面这张图描述了线程生命周期各个状态的转换： 在我们通过new创建了一个线程的实例过后，该线程就处于新建状态，此时这个线程对象就和其他Java对象一样，JVM为其分配内存，初始化成员变量的值。 调用线程对象的start()方法之后，线程进入就绪状态，Java虚拟机会为其创建栈帧和程序计数器，但是这个状态的线程也并没有开始运行，只是表明这个线程已经可以开始运行了，具体运行时间要看JVM的调度。这里千万要注意，启动线程要使用start()方法，而不是run()方法，使用start()方法启动系统会把run()方法当做线程执行体来执行，但是如果使用run()方法，相当于会立即执行run()方法，线程对象也只是一个普通对象，不会把run()方法包装成线程执行体来执行。 处于就绪状态的线程如果获取了CPU，那么就会进入运行状态，在这个状态的线程可能会调用sleep()方法进入阻塞，也可能调用yield()方法再次进入就绪状态，也可能完整地执行完成后进入死亡状态。如果线程进入死亡状态，就不能再次调用start()方法来启动它了，否则会抛出IllegalThreadStateExcetion异常。 处于阻塞状态的线程在sleep()时间结束、线程调用的阻塞式IO方法已经返回、线程成功获取锁、被notify()方法唤醒或者调用resume()方法之后会重新进入就绪状态。 结束前以上内容都是个人学习的总结，后面可能会补充更多，如果有错误，请指出。 参考: 《Java并发编程的艺术》 《疯狂Java讲义》]]></content>
      <categories>
        <category>Java Concurrency</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot中使用Redis的实践]]></title>
    <url>%2F2018%2F05%2F22%2FSpringBoot%E4%B8%AD%E4%BD%BF%E7%94%A8Redis%E7%9A%84%E5%AE%9E%E8%B7%B5%2F</url>
    <content type="text"><![CDATA[SpringBoot中使用Redis的实践 Redis是一个高性能的内存数据库，在日常开发中运用非常的广泛，主要用作缓存。Redis提供了非常丰富的数据结构，有String，List，Set，ZSet，Hash，Redis为这些数据结构提供了丰富的原子性操作。弥补了其他NoSQL如Memcached的不足。在SpringBoot中，由于Boot提供了强大的AutoConfiguration，集成Redis变得非常简单。本文将介绍Redis在SpringBoot中的应用，包括手动使用RedisTemplate进行操作，和使用注解（@Cacheable等）把业务数据缓存到Redis中。 开始环境：JDK1.8，Maven3+，Redis3需要预先安装好Redis，也可以使用Docker快速部署一个Redis，可以参考我之前的文章 新建一个SpringBoot项目，引入需要用到的相关maven依赖12345678910111213141516171819202122232425&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringBoot的Redis支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--SpringBoot缓存支持--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 在yaml文件中配置redis连接：1234567891011121314151617spring: redis: #Redis服务器地址，默认localhost host: localhost #Redis服务器端口，默认6379 port: 6379 pool: #连接池最大连接数 max-active: 8 #最大阻塞等待时间，-1表示没有限制 max-wait: -1 #最大空闲连接 max-idle: 8 #最小空闲连接 min-idle: 0 #连接超时时间 timeout: 0 使用RedisTemplate操作Redisspring-data-redis提供了一个RedisTemplate类，这个类封装了对Redis基本数据结构的常用操作，它的子类StringRedisTemplate提供了对字符串的常用操作，接下来将使用StringRedisTemplate来操作Redis中的String和List类型。 注入StringRedisTemplate12@Autowiredprivate StringRedisTemplate stringRedisTemplate; 12345678910111213141516171819202122232425/** * 操作字符串 */private void operateString() &#123; stringRedisTemplate.opsForValue().set("author", "luoliang"); String value = stringRedisTemplate.opsForValue().get("author"); log.info("stringRedisTemplate输出值：&#123;&#125;", value);&#125;/** * Redis List操作，Redis列表是简单的字符串列表，按照插入顺序排序。可以添加一个元素到列表的头部（左边）或者尾部（右边） */private void operateList() &#123; String key = "website"; ListOperations&lt;String, String&gt; listOperations = stringRedisTemplate.opsForList(); //从左压入栈 listOperations.leftPush(key, "Github"); listOperations.leftPush(key, "CSDN"); //从右压入栈 listOperations.rightPush(key, "SegmentFault"); log.info("list size:&#123;&#125;", listOperations.size(key)); List&lt;String&gt; list = listOperations.range(key, 0, 2); list.forEach(log::info);&#125; 上面涉及到的两种类型的操作，都是针对的字符串，可不可以存取对象呢？答案当然是可以的。我们使用Hash来存取对象，首先新建一个User类，用于存取使用。 此处需要注意，User类需要实现Serializable接口，否则无法序列化123456789@Data@Builderpublic class User implements Serializable &#123; private String id; private String name; private Integer age;&#125; 这时候就不能再使用StringRedisTemplate了，所以需要配置针对Object的RedisTemplate实例，这里可以使用默认的JdkSerializationRedisSerializer序列化，也可以自己实现RedisSerializer接口来自定义序列化1234567891011121314@Configurationpublic class RedisConfig &#123; @Resource private JedisConnectionFactory jedisConnectionFactory; @Bean public RedisTemplate&lt;String, Object&gt; objRedisTemplate() &#123; RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;(); template.setConnectionFactory(jedisConnectionFactory); template.setKeySerializer(new StringRedisSerializer()); template.setValueSerializer(new JdkSerializationRedisSerializer()); return template; &#125;&#125; 操作Hash1234567891011121314151617181920212223@Resourceprivate RedisTemplate&lt;String, Object&gt; objRedisTemplate;/** * 操作hash，存放User对象 */private void operateHash() &#123; String key = "user"; HashOperations&lt;String, String, User&gt; hashOperations = objRedisTemplate.opsForHash(); hashOperations.put(key, "user1", User.builder().name("Hulk").age(50).build()); hashOperations.put(key, "user2", User.builder().name("Thor").age(1500).build()); hashOperations.put(key, "user3", User.builder().name("Rogers").age(150).build()); log.info("hash size:&#123;&#125;", hashOperations.size(key)); log.info("--------拿到Map的key集合--------"); Set&lt;String&gt; keys = hashOperations.keys(key); keys.forEach(log::info); log.info("--------拿到Map的value集合--------"); List&lt;User&gt; users = hashOperations.values(key); users.forEach(user -&gt; log.info(user.toString())); log.info("--------拿到user1的value--------"); User user = hashOperations.get(key, "user1"); log.info(user.toString());&#125; 最后，验证我们的操作，可以看到，结果和预期相同。123456789101112131415161718192018-05-22 10:45:07.754 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : ----------Operate String----------2018-05-22 10:45:07.820 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : stringRedisTemplate输出值：luoliang2018-05-22 10:45:07.821 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : ----------Operate List----------2018-05-22 10:45:07.832 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : list size:572018-05-22 10:45:07.836 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : CSDN2018-05-22 10:45:07.836 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : Github2018-05-22 10:45:07.836 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : CSDN2018-05-22 10:45:07.836 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : ----------Operate Hash----------2018-05-22 10:45:07.858 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : hash size:32018-05-22 10:45:07.858 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : --------拿到Map的key集合--------2018-05-22 10:45:07.865 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : user22018-05-22 10:45:07.866 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : user12018-05-22 10:45:07.866 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : user32018-05-22 10:45:07.866 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : --------拿到Map的value集合--------2018-05-22 10:45:07.870 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : User(id=null, name=Thor, age=1500)2018-05-22 10:45:07.870 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : User(id=null, name=Hulk, age=50)2018-05-22 10:45:07.870 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : User(id=null, name=Rogers, age=150)2018-05-22 10:45:07.870 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : --------拿到user1的value--------2018-05-22 10:45:07.873 INFO 42127 --- [ main] org.boot.redis.BootRedisApplication : User(id=null, name=Hulk, age=50) 使用Annotation缓存数据上面的操作方式，是手动操作Redis进行存取，在真实的业务场景中，我们并不想这样去使用，而是把Redis当做一种缓存来使用，把service或者dao层的数据进行缓存，最简单的方式就是通过注解。在SpringBoot中使用Redis做缓存也非常简单，只需要在pom中引入spring-boot-starter-cache即可。 下面列出的是Spring缓存的常用注解（来自@程序猿DD）： @CacheConfig：主要用于配置该类中会用到的一些共用的缓存配置。在这里@CacheConfig(cacheNames = “users”)：配置了该数据访问对象中返回的内容将存储于名为users的缓存对象中，我们也可以不使用该注解，直接通过@Cacheable自己配置缓存集的名字来定义。 @Cacheable：配置了findByName函数的返回值将被加入缓存。同时在查询时，会先从缓存中获取，若不存在才再发起对数据库的访问。该注解主要有下面几个参数： value、cacheNames：两个等同的参数（cacheNames为Spring4新增，作为value的别名），用于指定缓存存储的集合名。由于Spring 4中新增了@CacheConfig，因此在Spring 3中原本必须有的value属性，也成为非必需项了 key：缓存对象存储在Map集合中的key值，非必需，缺省按照函数的所有参数组合作为key值，若自己配置需使用SpEL表达式，比如：@Cacheable(key = “#p0”)：使用函数第一个参数作为缓存的key值，更多关于SpEL表达式的详细内容可参考官方文档 condition：缓存对象的条件，非必需，也需使用SpEL表达式，只有满足表达式条件的内容才会被缓存，比如：@Cacheable(key = “#p0”, condition = “#p0.length() &lt; 3”)，表示只有当第一个参数的长度小于3的时候才会被缓存，若做此配置上面的AAA用户就不会被缓存，读者可自行实验尝试。 unless：另外一个缓存条件参数，非必需，需使用SpEL表达式。它不同于condition参数的地方在于它的判断时机，该条件是在函数被调用之后才做判断的，所以它可以通过对result进行判断。 keyGenerator：用于指定key生成器，非必需。若需要指定一个自定义的key生成器，我们需要去实现org.springframework.cache.interceptor.KeyGenerator接口，并使用该参数来指定。需要注意的是：该参数与key是互斥的 cacheManager：用于指定使用哪个缓存管理器，非必需。只有当有多个时才需要使用 cacheResolver：用于指定使用那个缓存解析器，非必需。需通过org.springframework.cache.interceptor.CacheResolver接口来实现自己的缓存解析器，并用该参数指定。 @CachePut：配置于函数上，能够根据参数定义条件来进行缓存，它与@Cacheable不同的是，它每次都会真实调用函数，所以主要用于数据新增和修改操作上。它的参数与@Cacheable类似，具体功能可参考上面对@Cacheable参数的解析。 @CacheEvict：配置于函数上，通常用在删除方法上，用来从缓存中移除相应数据。除了同@Cacheable一样的参数之外，它还有下面两个参数： allEntries：非必需，默认为false。当为true时，会移除所有数据 beforeInvocation：非必需，默认为false，会在调用方法之后移除数据。当为true时，会在调用方法之前移除数据。 由于本项目没有涉及到数据库的链接，下面，我们来模拟数据库的操作，并把结果缓存到Redis中123456789101112131415161718192021222324252627282930@Service@Slf4j@CacheConfig(cacheNames = "users")public class RedisCacheServiceImpl implements RedisCacheService &#123; @Override @CachePut(key = "#p0.id") public User save(User user) &#123; log.info("-----执行数据库更新操作"); log.info("-----数据库更新完成，返回结果"); return user; &#125; @Override @Cacheable(key = "#p0") public User get(String id) &#123; log.info("-----执行数据库查询操作"); User user = User.builder().id(id).name("spring").age(18).build(); log.info("-----数据库查询完成，返回结果"); return user; &#125; @Override @CacheEvict(key = "#p0") public void delete(String id) &#123; log.info("-----执行数据库删除操作"); log.info("-----数据库删除完成，返回结果"); &#125;&#125; 在Junit中进行测试123456789101112131415161718192021222324@SpringBootTest@RunWith(SpringJUnit4ClassRunner.class)@Slf4jpublic class RedisCacheServiceTest &#123; @Resource private RedisCacheService redisCacheService; @Test public void testGet() &#123; User user = redisCacheService.get("1111111"); log.info(user.toString()); &#125; @Test public void testSave() &#123; User user = User.builder().id("1111111").name("spring").age(20).build(); redisCacheService.save(user); &#125; @Test public void testDelete() &#123; redisCacheService.delete("1111111"); &#125;&#125; 先调用get方法，此时，Redis中没有此数据，会进入方法，拿到数据之后返回，并且把数据缓存到Redis中，结果如下：1232018-05-22 10:57:57.532 INFO 42313 --- [ main] o.b.r.s.impl.RedisCacheServiceImpl : -----执行数据库查询操作2018-05-22 10:57:57.533 INFO 42313 --- [ main] o.b.r.s.impl.RedisCacheServiceImpl : -----数据库查询完成，返回结果2018-05-22 10:57:57.557 INFO 42313 --- [ main] o.b.redis.service.RedisCacheServiceTest : User(id=1111111, name=spring, age=18) 再调用一次get方法，此时将不会进入方法中，直接从缓存中拿到数据并返回，结果如下：12018-05-22 10:57:57.557 INFO 42313 --- [ main] o.b.redis.service.RedisCacheServiceTest : User(id=1111111, name=spring, age=18) 再调用save方法，会把缓存中ID为1111111的User年龄更新为20，调用delete方法会删除缓存，和预期的结果一致，这里就不贴结果了，感兴趣的同学可以自行验证。 总结至此，整篇文章就结束了，文章包含了RedisTemplate的使用，以及Spring提供的@Cacheable等注解的使用，都是日常开发中常常用到的东西。 最后，附上github源码，欢迎star，一起交流。boot-redis]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring之IOC的注入方式]]></title>
    <url>%2F2018%2F05%2F09%2FSpring%E4%B9%8BIOC%E7%9A%84%E6%B3%A8%E5%85%A5%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Spring之IOC的注入方式 在java中，要使用一个对象，必须先创建一个实例，但是有了IOC之后，对象的创建与销毁都交给了IOC容器，不用我们手动创建，而是直接从IOC容器中获取，达到了解耦的效果。IOC是一种思想，在Spring中，实现IOC的方式是DI（依赖注入），本文会介绍Spring依赖注入的几种方式。 Spring的依赖注入对象，在Spring中叫做bean，即使是最简单的应用，也需要多个bean共同协作。依赖注入是指对象之间的依赖关系，一起协作的其他对象，通过构造器的参数、工厂方法的参数创建的对象，或者构造函数、工厂方法创建的对象来设置属性。所以容器的工作实际上就是创建bean并注入依赖关系。Spring中的DI方式主要有两种，构造器注入和Setter注入。 项目准备新建一个maven项目，JDK版本1.8，引入Spring的核心依赖12345678910111213141516171819&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 构造器注入 新建一个User类作为注入的例子，添加get，set方法，重写toString方法，添加两个参数不同的构造器。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class User &#123; private String id; private String name; private Integer age; public User(String id, String name) &#123; this.id = id; this.name = name; &#125; public User(String name, Integer age) &#123; this.name = name; this.age = age; &#125; public String getId() &#123; return id; &#125; public void setId(String id) &#123; this.id = id; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; @Override public String toString() &#123; return "User&#123;" + "id='" + id + '\'' + ", name='" + name + '\'' + ", age=" + age + '&#125;'; &#125;&#125; xml配置如下，有三种不同的写法在resource下面新建application-constructor.xml 123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.springframework.org/schema/beans" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!--构造方法注入--&gt; &lt;!--使用index属性来显式指定构造参数的索引--&gt; &lt;bean id="user1" class="org.spring.ioc.entity.User"&gt; &lt;constructor-arg index="0" value="1234"/&gt; &lt;constructor-arg index="1" value="spring"/&gt; &lt;/bean&gt; &lt;!--使用type属性显式指定简单类型的构造器参数类型，这里对应的是User类中传入name,age的构造器--&gt; &lt;bean id="user2" class="org.spring.ioc.entity.User"&gt; &lt;constructor-arg type="java.lang.String" value="spring"/&gt; &lt;constructor-arg type="java.lang.Integer" value="20"/&gt; &lt;/bean&gt; &lt;!--也可以使用构造器参数命名来指定值的类型--&gt; &lt;bean id="user3" class="org.spring.ioc.entity.User"&gt; &lt;constructor-arg name="id" value="1234"/&gt; &lt;constructor-arg name="name" value="spring"/&gt; &lt;/bean&gt;&lt;/beans&gt; 在bean的constructor-arg元素下进行指定，constructor-arg顾名思义就是构造器参数的意思，其中包括了三个属性配置 index 是一个索引顺序，对应构造器参数的索引，根据索引进行注入 type 构造器的参数类型，可以通过类型进行匹配注入 name 构造器参数名，根据名称进行匹配注入 验证现在可以启动Spring容器来验证bean是否注入成功12345678910111213141516171819public class Main &#123; private final static String APPLICATION = "classpath:application-*.xml"; public static void main(String[] args) &#123; //加载xml配置文件 ApplicationContext context = new ClassPathXmlApplicationContext(APPLICATION); constructorInject(context); &#125; private static void constructorInject(ApplicationContext context) &#123; //获取bean实例，传入的参数值为xml中配置的id User user1 = (User) context.getBean("user1"); System.out.println(user1.toString()); User user2 = (User) context.getBean("user2"); System.out.println(user2.toString()); User user3 = (User) context.getBean("user3"); System.out.println(user3.toString()); &#125;&#125; 输出结果如下：123User&#123;id='1234', name='spring', age=null&#125;User&#123;id='null', name='spring', age=20&#125;User&#123;id='1234', name='spring', age=null&#125; 可以看出我们定义的User对象已经成功交给Spring容器管理 Setter注入Setter注入也需要在xml中进行配置，在调用了无参的构造方法或者无参的静态工厂方法实例化bean之后，容器通过回调bean的setter方法来完成setter注入。 接下来新建Blog，Author两个类，添加get，set方法，重写toString方法：Blog类：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class Blog &#123; private String name; private String content; private Long date; private Author author; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getContent() &#123; return content; &#125; public void setContent(String content) &#123; this.content = content; &#125; public Long getDate() &#123; return date; &#125; public void setDate(Long date) &#123; this.date = date; &#125; public Author getAuthor() &#123; return author; &#125; public void setAuthor(Author author) &#123; this.author = author; &#125; @Override public String toString() &#123; return "Blog&#123;" + "name='" + name + '\'' + ", content='" + content + '\'' + ", date=" + date + ", author=" + author + '&#125;'; &#125;&#125; Author类：12345678910111213141516171819202122232425262728293031323334353637383940public class Author &#123; private String name; private Integer age; private String url; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125; public String getUrl() &#123; return url; &#125; public void setUrl(String url) &#123; this.url = url; &#125; @Override public String toString() &#123; return "Author&#123;" + "name='" + name + '\'' + ", age=" + age + ", url='" + url + '\'' + '&#125;'; &#125;&#125; xml配置setter注入是通过在bean下面配置property元素来完成的，在resource下面新建application-setter.xml12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://www.springframework.org/schema/beans" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;!--setter注入--&gt; &lt;bean id="blog" class="org.spring.ioc.entity.Blog"&gt; &lt;property name="name" value="spring-ioc"/&gt; &lt;property name="content" value="spring"/&gt; &lt;property name="date" value="1520232449944"/&gt; &lt;property name="author" ref="author"/&gt; &lt;/bean&gt; &lt;bean id="author" class="org.spring.ioc.entity.Author"&gt; &lt;property name="name" value="luoliang"/&gt; &lt;property name="age" value="18"/&gt; &lt;property name="url" value="https://meua.github.io"/&gt; &lt;/bean&gt;&lt;/beans&gt; 配置很简单，通过制定property元素的name和value属性，设置变量名对应的值，其中author属性引用的另一个bean，所以使用了ref属性。 验证1234567891011121314public class Main &#123; private final static String APPLICATION = "classpath:application-*.xml"; public static void main(String[] args) &#123; //加载xml配置文件 ApplicationContext context = new ClassPathXmlApplicationContext(APPLICATION); setterInject(context); &#125; private static void setterInject(ApplicationContext context) &#123; Blog blog = (Blog) context.getBean("blog"); System.out.println(blog.toString()); &#125;&#125; 结果如下：1Blog&#123;name='spring-ioc', content='spring', date=1520232449944, author=Author&#123;name='luoliang', age=18, url='https://meua.github.io'&#125;&#125; 所有我们配置的属性都注入成功。 总结我们可以混合使用构造器注入和Setter注入，最佳实践是强制性依赖关系时使用构造器注入，可选的依赖关系时使用Setter注入，在setter注入中可以使用@Required注解让属性成为必须的依赖项。有很多小伙伴会觉得很奇怪，明明使用注解进行配置依赖更加的简单。不否认，SpringBoot推出之后，Spring已经不再推荐xml配置，而是提倡java配置和注解，但是xml配置是Spring的基础。正是因为传统的Spring应用xml配置太过于复杂，才会出现SpringBoot这门技术来解决这些问题，一个技术的兴起是有各种原因的。SpringBoot虽然解决了配置复杂的问题，但是对于刚入门的人来说，不知道其中的细节，这可能并不是一个好的开始。上面用到的ApplicationContext，它所管理的beans支持构造函数注入和setter注入，在一些依赖已经使用构造器注入之后它还支持setter注入。我们也可以用BeanDefinition的形式配置依赖，它能根据指定的PropertyEditor实现将属性从一种格式转化为另外一种格式。但是，在日常的开发中我们不会直接以编程的方式去创建bean，而是采用上面所讲的xml配置创建bean，或者是通过注解（即@Component，@Service等注解类），或者基于@Configuration类的@Bean方法。本质上这些资源会转换成BeanDefinition的实例并且用于加载整个Spring IoC容器实例。所以，不管我们在传统Spring应用还是SpringBoot中，使用Spring的IOC，它的原理都是不会变的。 源码上面所用到的代码我已放在我的github上，欢迎star，一起学习，共同进步，如有不对之处，欢迎指出。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
        <tag>IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java设计模式-代理模式]]></title>
    <url>%2F2018%2F05%2F08%2FJava%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F-%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[设计模式之代理模式 代理模式是设计模式的一种，简单解释就是不直接访问目标对象，通过访问代理对象就可以实现对目标对象的访问。就像现在买火车票，不用直接去火车站买，可以直接去各个代售点或者APP上购买，这里的代售点或者APP就是火车站的代理，这样做的好处是，不用修改目标对象，可以在代理对象中增加额外的操作，达到扩展目标对象的目的 Java中主要有三种方式：静态代理，JDK动态代理，cglib代理。前两种代理方式都是通过接口代理，cglib可以实现代理类。 静态代理静态代理中代理对象和被代理对象都需要实现同一个接口，才能达到代理的目的。 这样做就会存在不好的地方，当修改接口时，代理对象和被代理对象都需要修改，耦合性太大，不容易维护，同时可能会产生过多的代理类。 静态代理代码实现定义一个接口： 1234public interface IBaseDao &#123; //存储数据方法 void save();&#125; 需要代理的目标类，需要实现IBaseDao接口： 123456public class StaticProxyTarget implements IBaseDao &#123; @Override public void save() &#123; System.out.println("save data"); &#125;&#125; 代理类，需要实现IBaseDao接口： 123456789101112131415public class StaticProxy implements IBaseDao &#123; //代理目标对象 private StaticProxyTarget target; //通过构造函数传入代理对象 public StaticProxy(StaticProxyTarget target) &#123; this.target = target; &#125; @Override public void save() &#123; System.out.println("start transaction"); target.save(); System.out.println("commit transaction"); &#125;&#125; 测试静态代理： 123456789public class ProxyTest &#123; public static void main(String[] args) &#123; //目标对象 StaticProxyTarget staticProxyTarget = new StaticProxyTarget(); //代理对象 StaticProxy staticProxy = new StaticProxy(staticProxyTarget); staticProxy.save(); &#125;&#125; 输出结果： 123start transactionsave datacommit transaction JDK动态代理JDK动态代理是利用Java API，动态的生成代理对象，达到代理目标对象的作用。 与静态代理不同的是，动态代理是在Java运行时动态生成字节码，并加载到jvm中运行，没有.class文件，静态代理编译后会产生.class文件。 定义一个接口： 123public interface IBaseDao &#123; void save();&#125; 需要代理的目标类，需要实现IBaseDao接口：1234567public class DynamicProxyTarget implements IBaseDao&#123; @Override public void save() &#123; System.out.println("save data"); &#125;&#125; 动态代理类：其中Proxy提供了用于创建动态代理对象的static方法。主要用到了下面这个方法，可以直接创建一个动态代理对象，该代理对象的实现类实现了interfaces指定的系列接口，执行代理对象的每个方法时都会被替换成InvocationHandler的invoke方法。123static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) 12345678910111213141516171819202122232425public class DynamicProxy &#123; //需要代理的目标对象 private Object target; public DynamicProxy(Object target) &#123; this.target = target; &#125; public Object getProxyInstance() &#123; /** * 执行动态代理对象的方法时，将会执行InvocationHandler的invoke方法 * 其中三个参数为 * proxy：动态代理对象 * method：代表正在执行的方法 * args：调用目标对象方法时传入的参数 */ return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), (proxy, method, args) -&gt; &#123; System.out.println("start transaction"); //调用目标对象的方法 Object result = method.invoke(target, args); System.out.println("commit transaction"); return result; &#125;); &#125;&#125; 测试JDK动态代理： 12345678public class ProxyTest &#123; public static void main(String[] args) &#123; //动态代理测试 IBaseDao baseDao = new DynamicProxyTarget(); IBaseDao dynamicProxy = (IBaseDao) new DynamicProxy(baseDao).getProxyInstance(); dynamicProxy.save(); &#125;&#125; 结果输出： 123start transactionsave datacommit transaction cglib代理cglib (Code Generation Library )是一个第三方代码生成类库，可以在运行时在内存中动态生成一个子类对象，从而实现对目标对象功能的扩展。Spring框架中的AOP就使用了cglib。 cglib和上面两种代理最大的不同就是，被代理类不需要实现接口，就可以实现对目标对象的代理，代码侵入性更小。 需要代理的目标类： 12345public class CglibProxyTarget &#123; public void save() &#123; System.out.println("save data"); &#125;&#125; cglib代理类，需要实现MethodInterceptor接口： 123456789101112131415161718192021222324252627public class CglibProxy implements MethodInterceptor &#123; private CglibProxyTarget target; public CglibProxy(CglibProxyTarget target) &#123; this.target = target; &#125; //生成代理对象 public Object getProxyInstance() &#123; Enhancer enhancer = new Enhancer(); //指定父类 enhancer.setSuperclass(target.getClass()); //设置回调 enhancer.setCallback(this); return enhancer.create(); &#125; @Override public Object intercept(Object o, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; System.out.println("start transaction"); //调用目标对象的方法 Object result = method.invoke(target, args); System.out.println("commit transaction"); return result; &#125;&#125; 测试结果： 12345678public class ProxyTest &#123; public static void main(String[] args) &#123; //cglib代理测试 CglibProxyTarget cglibProxyTarget = new CglibProxyTarget(); cglibProxyTarget = (CglibProxyTarget) new CglibProxy(cglibProxyTarget).getProxyInstance(); cglibProxyTarget.save(); &#125;&#125; 结果输出： 123start transactionsave datacommit transaction 总结 静态代理代理对象和被代理对象都需要实现同一个接口，实现简单，但是耦合性太大，不便于维护。 JDK动态代理需要被代理对象实现业务接口，代理对象中实现InvocationHandler接口，通过Java反射生成代理，但是动态生成的代理更加灵活。 静态代理编译后产生.class文件，比JDK反射性能好，cglib是通过字节码生成代理，性能高于反射，但是cglib会生成子类继承被代理对象，所以被代理对象不能为final。 代码很简单，需要理解的是思想，代理模式运用广泛，很多框架中都使用了代理模式，只是设计更复杂，个人笔记，如有不对请指出。]]></content>
      <categories>
        <category>design pattern</category>
      </categories>
      <tags>
        <tag>设计模式</tag>
        <tag>代理模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis3集群搭建（下）- 实操]]></title>
    <url>%2F2018%2F05%2F07%2FRedis3%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%EF%BC%88%E4%B8%8B%EF%BC%89-%E5%AE%9E%E6%93%8D%2F</url>
    <content type="text"><![CDATA[Redis3集群搭建（下）- 实操上一篇博客学习了一些Redis集群的基础知识，这篇文章将会开始学习搭建一个3主3从的小型的Redis集群。 准备 Redis 3.2.9 一台机器，Linux或者macOS 我本机是macOS，所以这里以macOS为例。 安装1234$ wget http://download.redis.io/releases/redis-3.2.9.tar.gz$ tar xzf$ cd redis-3.2.9/$ make 编译完成后，就可以启动Redis了1$ src/redis-server redis.conf 启动完成，说明Redis已经可以使用了。 配置文件还需要准备一些配置文件供Redis集群使用，Redis集群搭建需要六个运行在Redis集群模式下的Redis实例，而不是普通的Redis实例，所以需要通过修改配置文件来让Redis实例支持集群。123$ mkdir redis-cluster$ cd redis-cluster$ mkdir 7000 7001 7002 7003 7004 7005 在7000-7005这几个文件夹中各创建一个redis.conf文件，文件的内容可以使用最开始解压后文件夹中的redis.conf文件，在这个基础上进行修改。需要修改如下几个配置：12345port 7000cluster-enabled yescluster-config-file nodes-7000.confcluster-node-timeout 15000appendonly yes cluster-enabled:配置打开集群模式 cluster-enabled:配置保存节点配置文件的路径，默认值为nodes.conf，无需人为修改，它由Redis集群启动时创建，并在有需要时自动进行更新 appendonly:打开持久化 其他文件夹的配置以此类推，将可执行文件redis-server复制到redis-cluster文件夹下面，然后使用以下命令，一次在每个文件夹下面执行：12$ cd 7000$ ../redis-server ./redis.config 搭建集群把所有实例都运行起来之后，就可以使用这些实例开始搭建集群了，同时为每个节点编写配置文件。使用 Redis集群命令行工具redis-trib，编写节点配置文件可以变得非常简单。redis-trib.rb在Redis源码的src目录下，他是用ruby编写的，可以通过它来对Redis集群进行创建、检查、分片等工作。所以本机还需要安装配置ruby环境（ps：ruby环境配置后，需要安装Ruby的Redis接口，使用命令gem install redis）。 Ruby方式创建集群：12./redis-trib.rb create --replicas 1 127.0.0.1:7000 127.0.0.1:7001 \127.0.0.1:7002 127.0.0.1:7003 127.0.0.1:7004 127.0.0.1:7005 这个命令在这里用于创建一个新的集群，–replicas 1表示为集群中的每个主节点创建一个从节点。redis-trib这时候会打印出一份预想中的配置给你看，如果觉得没有问题，输入yes，集群就开始创建了。如下图所示，表示集群创建成功： create-cluster脚本如果觉得这种方式太麻烦，也可以通过Redis源码目录下的utils/create-cluster文件夹中的create-cluster脚本创建集群。通过这个脚本可以创建一个3主3从的集群，并且端口默认从30001开始。但是通过这种方式就不能学习到那么多Redis集群的细节。这个脚本主要有以下命令： create-cluster start create-cluster create create-cluster stop 测试集群这里用redis-cli脚本进行测试，看集群是否可用。1234567891011121314$ ./redis-cli -c -p 7000127.0.0.1:7000&gt; set mykey redis-&gt; Redirected to slot [14687] located at 127.0.0.1:7002OK127.0.0.1:7002&gt; set hello world-&gt; Redirected to slot [866] located at 127.0.0.1:7000OK127.0.0.1:7000&gt; get mykey-&gt; Redirected to slot [14687] located at 127.0.0.1:7002"redis"127.0.0.1:7002&gt; get hello-&gt; Redirected to slot [866] located at 127.0.0.1:7000"world"127.0.0.1:7000&gt; 可以看出Redis会根据key计算对应的slot，然后跳转到对应的node上去，和我们之前介绍的内容一致。 至此，一个3主3从的Redis集群就搭建完成了，接下来可能会写一篇使用Docker搭建Redis集群的文章。参考 http://www.redis.cn/]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Redis集群</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis3集群搭建（上）- 基础知识]]></title>
    <url>%2F2018%2F05%2F07%2FRedis3%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA%EF%BC%88%E4%B8%8A%EF%BC%89-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%2F</url>
    <content type="text"><![CDATA[Redis3集群搭建（上）- 基础知识 随着项目规模越来越大，单个Redis已经不能满足需求。Redis从3.0版本之后开始支持集群模式，可以进行分布式存储，本文将介绍一些Redis集群的基础知识，再从0开始搭建一个Redis集群。 Redis集群介绍Redis集群是一个提供在多个Redis间节点间共享数据的程序集。Redis集群并不支持处理多个keys的命令,因为这需要在不同的节点间移动数据,从而达不到像Redis那样的性能,在高负载的情况下可能会导致不可预料的错误。Redis集群通过分区来提供一定程度的可用性,在实际环境中当某个节点宕机或者不可达的情况下继续处理命令. Redis集群的优势: 自动分割数据到不同的节点上。 整个集群的部分节点失败或者不可达的情况下能够继续处理命令。Redis集群分片Redis集群没有使用一致性hash, 而是引入了哈希槽的概念。Redis集群有16384个哈希槽,每个key通过CRC16校验后对16384取模来决定放置哪个槽。（有点类似于Java的HashMap，通过取模计算具体的槽位）集群的每个节点负责一部分hash槽,举个例子,比如当前集群有3个节点,那么: 节点A包含0到5500号哈希槽 节点B包含5501到11000 号哈希槽 节点C包含11001到16384号哈希槽 这种结构很容易添加或者删除节点。比如如果我想新添加一个节点D, 我需要从节点A, B, C中移动部分槽到D上。如果我想移除节点A，需要将A中的槽移到B和C节点上,然后将没有任何槽的A节点从集群中移除即可。由于从一个节点将哈希槽移动到另一个节点并不会停止服务,所以无论添加删除或者改变某个节点的哈希槽的数量都不会造成集群不可用的状态. Redis集群主从复制模型为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模型,每个节点都会有N-1个复制品。在我们例子中具有A，B，C三个节点的集群,在没有复制模型的情况下,如果节点B失败了，那么整个集群就会以为缺少5501-11000这个范围的槽而不可用。如果在集群创建的时候（或者过一段时间）我们为每个节点添加一个从节点A1，B1，C1,那么整个集群便有三个master节点和三个slave节点组成，这样在节点B失败后，集群便会选举B1为新的主节点继续服务，整个集群便不会因为槽找不到而不可用了。不过当B和B1 都失败后，集群是不可用的。 Redis一致性保证Redis 并不能保证数据的强一致性，这意味这在实际中集群在特定的条件下可能会丢失写操作。第一个原因是因为集群是用了异步复制. 写操作过程: 客户端向主节点B写入一条命令。 主节点B向客户端回复命令状态。 主节点将写操作复制给他得从节点 B1, B2 和 B3。 主节点对命令的复制工作发生在返回命令回复之后，因为如果每次处理命令请求都需要等待复制操作完成的话，那么主节点处理命令请求的速度将极大地降低， 所以必须在性能和一致性之间做出权衡。注意：Redis集群可能会在将来提供同步写的方法。 Redis集群另外一种可能会丢失命令的情况是集群出现了网络分区，并且一个客户端与至少包括一个主节点在内的少数实例被孤立。举个例子 假设集群包含A、B、C、A1、B1、C1六个节点，其中A、B 、C为主节点，A1、B1 、C1为A，B，C的从节点，还有一个客户端Z1假设集群中发生网络分区，那么集群可能会分为两方，大部分的一方包含节点A 、C 、A1 、B1和C1，小部分的一方则包含节点B和客户端Z1。Z1仍然能够向主节点B中写入, 如果网络分区发生时间较短,那么集群将会继续正常运作,如果分区的时间足够让大部分的一方将B1选举为新的master，那么Z1写入B中得数据便丢失了。在网络分裂出现期间， 客户端Z1可以向主节点B发送写命令的最大时间是有限制的， 这一时间限制称为节点超时时间（node timeout），是Redis集群的一个重要的配置选项。 本文介绍了一些Redis集群的基本知识，下一篇将开始动手搭建Redis的集群。参考 http://www.redis.cn/]]></content>
      <categories>
        <category>Ops</category>
      </categories>
      <tags>
        <tag>Redis集群</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初探Protostuff的使用]]></title>
    <url>%2F2018%2F05%2F02%2F%E5%88%9D%E6%8E%A2Protostuff%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[初探Protostuff的使用 最近在学习RPC，看到了一个叫做Protostuff的库，是基于谷歌Protocal Buffer的序列化库，之前了解过Protocol Buffer，对学习了一些资料后，写了个demo，记录下来。 什么是Protocol Buffer？Protocol Buffer是谷歌出品的一种数据交换格式，独立于语言和平台，类似于json。Google提供了多种语言的实现：java、c++、go和python。对象序列化城Protocol Buffer之后可读性差，但是相比xml，json，它占用小，速度快。适合做数据存储或 RPC 数据交换格式。 Java序列化库 - Protostuff相对我们常用的json来说，Protocol Buffer门槛更高，因为需要编写.proto文件，再把它编译成目标语言，这样使用起来就很麻烦。但是现在有了protostuff之后，就不需要依赖.proto文件了，他可以直接对POJO进行序列化和反序列化，使用起来非常简单。 实战新建一个SpringBoot的项目，再引入Protostuff的依赖1234567891011&lt;dependency&gt; &lt;groupId&gt;io.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-core&lt;/artifactId&gt; &lt;version&gt;$&#123;protostuff.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.protostuff&lt;/groupId&gt; &lt;artifactId&gt;protostuff-runtime&lt;/artifactId&gt; &lt;version&gt;$&#123;protostuff.version&#125;&lt;/version&gt; &lt;/dependency&gt; 先编写两个POJO，再把它们嵌套起来，这里使用了lombok的@Data注解和@Builder注解，@Data可以自动生成getter setter，@Builder注解可以让我们通过更加优雅的构建者模式来创建对象。1234567891011@Data@Builderpublic class User &#123; private String id; private String name; private Integer age; private String desc;&#125; 123456789@Data@Builderpublic class Group &#123; private String id; private String name; private User user;&#125; 接下来编写Protostuff序列化工具类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public class ProtostuffUtils &#123; /** * 避免每次序列化都重新申请Buffer空间 */ private static LinkedBuffer buffer = LinkedBuffer.allocate(LinkedBuffer.DEFAULT_BUFFER_SIZE); /** * 缓存Schema */ private static Map&lt;Class&lt;?&gt;, Schema&lt;?&gt;&gt; schemaCache = new ConcurrentHashMap&lt;&gt;(); /** * 序列化方法，把指定对象序列化成字节数组 * * @param obj * @param &lt;T&gt; * @return */ @SuppressWarnings("unchecked") public static &lt;T&gt; byte[] serialize(T obj) &#123; Class&lt;T&gt; clazz = (Class&lt;T&gt;) obj.getClass(); Schema&lt;T&gt; schema = getSchema(clazz); byte[] data; try &#123; data = ProtostuffIOUtil.toByteArray(obj, schema, buffer); &#125; finally &#123; buffer.clear(); &#125; return data; &#125; /** * 反序列化方法，将字节数组反序列化成指定Class类型 * * @param data * @param clazz * @param &lt;T&gt; * @return */ public static &lt;T&gt; T deserialize(byte[] data, Class&lt;T&gt; clazz) &#123; Schema&lt;T&gt; schema = getSchema(clazz); T obj = schema.newMessage(); ProtostuffIOUtil.mergeFrom(data, obj, schema); return obj; &#125; @SuppressWarnings("unchecked") private static &lt;T&gt; Schema&lt;T&gt; getSchema(Class&lt;T&gt; clazz) &#123; Schema&lt;T&gt; schema = (Schema&lt;T&gt;) schemaCache.get(clazz); if (Objects.isNull(schema)) &#123; //这个schema通过RuntimeSchema进行懒创建并缓存 //所以可以一直调用RuntimeSchema.getSchema(),这个方法是线程安全的 schema = RuntimeSchema.getSchema(clazz); if (Objects.nonNull(schema)) &#123; schemaCache.put(clazz, schema); &#125; &#125; return schema; &#125;&#125; 验证序列化功能12345678910111213141516171819@SpringBootApplicationpublic class Application implements CommandLineRunner &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Override public void run(String... strings) throws Exception &#123; //创建一个user对象 User user = User.builder().id("1").age(20).name("张三").desc("programmer").build(); //创建一个Group对象 Group group = Group.builder().id("1").name("分组1").user(user).build(); //使用ProtostuffUtils序列化 byte[] data = ProtostuffUtils.serialize(group); System.out.println("序列化后：" + Arrays.toString(data)); Group result = ProtostuffUtils.deserialize(data, Group.class); System.out.println("反序列化后：" + result.toString()); &#125;&#125; 可以看到控制台打印出如下数据，说明序列化和反序列化成功123序列化后：[10, 1, 49, 18, 7, -27, -120, -122, -25, -69, -124, 49, 27, 10, 1, 49, 18, 6, -27, -68, -96, -28, -72, -119, 24, 20, 34, 10, 112, 114, 111, 103, 114, 97, 109, 109, 101, 114, 28]反序列化后：Group(id=1, name=分组1, user=User(id=1, name=张三, age=20, desc=programmer)) 最后，代码在这里地址，欢迎star。 参考 https://github.com/protostuff/protostuff]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>序列化</tag>
        <tag>Protostuff</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Docker部署Redis]]></title>
    <url>%2F2018%2F04%2F26%2F%E4%BD%BF%E7%94%A8Docker%E9%83%A8%E7%BD%B2Redis%2F</url>
    <content type="text"><![CDATA[使用Docker部署Redis拉取镜像这里以Redis3.2版本为例1docker pull redis:3.2 运行容器1docker run -d -p 6379:6379 -v $PWD/data:/data --name redis redis:3.2 redis-server --appendonly yes 这里对部分命令做一下说明： -p 6379:6370: 将容器的6379端口映射到宿主机的6379端口 -v $PWD/data:/data: 将主机中当前目录下的data挂载到容器的/data，这样做是为了持久化容器内的数据 redis-server –appendonly yes : 在容器执行redis-server启动命令，并打开redis持久化配置 这里就会有一个问题，可以使用使用自定义的redis.conf配置吗？答案当然是可以的。可以通过两种方式来实现，一种是自定义的Dockerfile，另一种是直接通过docker run命令来进行指定，首先需要在本机准备好一个redis.conf。 Dockerfile 123FROM redisCOPY redis.conf /usr/local/etc/redis/redis.confCMD [ "redis-server", "/usr/local/etc/redis/redis.conf" ] docker run 1docker run -v $PWD/redis.conf:/usr/local/etc/redis/redis.conf --name redis redis redis-server /usr/local/etc/redis/redis.conf 这时候查看Redis容器启动状况：1docker ps 123$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES21d1f921e382 redis:3.2 "docker-entrypoint.s…" Less than a second ago Up 2 seconds 0.0.0.0:6379-&gt;6379/tcp admiring_bose 容器交互在Redis容器启动成功后，可以通过redis-cli命令连接到容器使用命令进入容器12$ docker exec -it redis redis-cli127.0.0.1:6379&gt; info 此时可以看到terminal输出了Redis容器的基础信息，说明Redis容器已经可以使用了，也可以使用Redis客户端连接Redis容器，地址是: $ip:6379]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>Docker</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP其实很简单]]></title>
    <url>%2F2018%2F04%2F24%2FSpring-AOP%E5%85%B6%E5%AE%9E%E5%BE%88%E7%AE%80%E5%8D%95%2F</url>
    <content type="text"><![CDATA[Spring AOP其实很简单什么是AOPAOP（Aspect-Oriented Programming），面向切面编程，是OOP的补充和完善。OOP允许定义从上到下的关系，但并不适合从左到右的关系。比如日志功能，日志的记录往往散步在系统的各个地方，如果用OOP来实现，就会出现大量重复的代码，而这些记录日志的动作和核心业务没有直接的关系，这时候就需要AOP，对所有记录日志的动作进行一种称为“横切”的操作。就是用这种“横切”的操作，剖解开对象内部，将那些影响多个类的公共行为封装到一个可重用的模块，命名为“Aspect”，即方面。就是将那些与业务无关，却为业务模块所共用的逻辑，封装起来，减少代码的重复，同时降低系统耦合度。 下面以几张图来说明AOP的作用： 在日常的开发中，多个业务逻辑会存在相同代码的情况，这时候屌丝程序员就会进行一个操作-复制-&gt;粘贴-&gt;大功告成！ 这样就会存在一个问题，如果这些相同的代码块需要修改，如果只有两三个业务逻辑使用的话还好，如果有成千上万个需要改，那这种做法是很难维护的。 这时候普通程序员出来了，觉得这样相同的代码逻辑可以提出来，单独写在一个方法里面，这样每一个需要使用这个代码块的业务直接调用方法就好了，就算以后要修改，也只需要改一个方法。 这样的方法极大地提高了系统的可维护性，但是也存在一个问题，每个业务逻辑调用这个方法，那么这些业务逻辑就和这个方法以硬编码的方式强耦合了。 这时候文艺程序员站了出来，他觉得我们可以使用AOP来达到一种效果，这些业务逻辑不需要自己去调用这个方法，它们只需要执行自己主要的业务，而相同的这部分代码块，通过AOP动态的织入业务中，起到一种对原有业务增强的作用。 OOP和AOP 概念 OOP Object-Oriented Programming 面向对象编程 AOP Aspect-Oriented Programming 面向切面编程 方向 OOP定义从上到下的关系 AOP定义从左到右的关系 核心关注点 OOP - 业务处理的主要流程，与业务主要流程关系不大的部分 AOP - 经常发生在核心关注点的多处，而各处都基本相似，比如权限，日志，事务处理 AOP主要使用场景 缓存代理，缓存某方法的返回值，下次执行该方法时，直接从缓存里获取。 记录日志，在方法执行前后记录系统日志。 权限验证，方法执行前验证是否有权限执行当前方法，没有则抛出没有权限执行异常，由业务代码捕捉。 Spring AOP重要概念 名词 Aspect（切面）：一个关注点的模块化，这个关注点会横切多个对象。 Joinpoint（连接点）：在程序执行过程中某个特定的点，比如某方法调用的时候。 Pointcut（切入点）：匹配连接点的断言，Advice和一个Pointcut表达式关联，并在满足这个Pointcut的Jointpoint上运行。 Introduction（引入）：用来给一个类型声明额外的方法或属性。Spring可以引入新的接口到任何被代理的对象。 Target Object（目标对象）：被一个或多个切面所通知的对象，Spring AOP是通过运行时代理实现的，所以这个对象永远是一个被代理对象。 AOP proxy（AOP 代理）：AOP框架动态创建的对象，用来执行切面所定义的方法。在Spring中，AOP代理可以是JDK动态代理或者Cglib动态代理。 Weaving（织入）：把切面连接到其他的应用程序类型或者对象上，并创建一个被通知的对象。这些可以在编译时、类加载时或者运行时完成。Spring是在运行时完成的织入。 Advice（通知）：在切面的某个特定的连接点上执行的动作。 通知类型 Before advice（前置通知）：在某连接点之前执行的通知，但这个通知不能阻止连接点之前执行的流程（除开抛出异常）。 After returning advice（后置通知）：在某连接点正常完成后执行的通知，一个方法正常返回后，没有异常。 After throw advice（异常通知）：在方法抛出异常时执行的通知。 After advice（最终通知）：当某连接点退出的时候执行的通知，不论是正常返回还是异常退出。 Around advice（环绕通知）：包围一个连接点的通知，如方法调用。环绕通知可以在方法调用前后完成自定义的行为。他也可以选择是否执行连接点或直接返回他自己的返回值或抛出异常来结束执行。 实例 AOP事务的实现 接下来通过注解的方式来使用Spring AOP，模拟在Service层数据库操作前后事务以及日志记录的执行。 新建一个SpringBoot的项目，并且在pom中引入AOP需要的依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 定义一个切面类，用于在方法前后进行记录日志和事务的操作 12345678910111213141516171819202122232425262728293031323334353637383940@Aspect@Componentpublic class TransactionAspect &#123; /** * 切入点 * execution表达式匹配org.boot.aop.service包下所有类的所有方法，包括任意参数 */ @Pointcut("execution(* org.boot.aop.service..*(..))") public void pointcut() &#123; &#125; /** * 前置通知 */ @Before("pointcut()") public void before() &#123; System.out.println("前置通知----&gt;开始事务"); &#125; /** * 后置通知 */ @AfterReturning("pointcut()") public void afterReturning() &#123; System.out.println("后置通知----&gt;提交事务"); &#125; /** * 环绕通知 * * @param joinPoint * @throws Throwable */ @Around("pointcut()") public void around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println("环绕通知----&gt;开始事务"); joinPoint.proceed(); System.out.println("环绕通知----&gt;提交事务"); &#125;&#125; 切面类写好之后，在对应的service包下建一个DataServic，变编写一个测试方法 12345678910@Servicepublic class DatabaseService &#123; /** * 模拟数据库的添加操作 */ public void add() &#123; System.out.println("执行添加操作..."); &#125;&#125; 执行 这里需要加上一个EnableAspectJAutoProxy注解，用于开启AOP代理自动配置123456789101112131415@SpringBootApplication@EnableAspectJAutoProxypublic class BootAopApplication implements CommandLineRunner&#123; @Resource private DatabaseService databaseService; public static void main(String[] args) &#123; SpringApplication.run(BootAopApplication.class, args); &#125; @Override public void run(String... strings) throws Exception &#123; databaseService.add(); &#125;&#125; 输出结果如下： 12345环绕通知----&gt;开始事务前置通知----&gt;记录方法开始日志执行添加操作...环绕通知----&gt;提交事务后置通知----&gt;记录方法结束日志 可以看出来在Spring中使用AOP，在简化了我们重复编写事务和日志代码的同时，也大大降低了代码的耦合度，我们的service层中并没有编写任何事务和日志有关的代码，通过动态切入，就完成了这两个功能，如果是日后需要重构，也只需要修改切面类的代码，维护起来也很容易。 原理Spring的AOP主要实现原理其实就是动态代理，通过代理对目标类的指定方法进行增强处理。Spring主要使用了两种动态代理，一种是JDK动态代理，另一种是Cglib动态代理。Spring默认的策略是JDK动态代理，这时目标类必须是接口或接口的实现类，否则Spring将使用Cglib进行动态代理，上面的例子中，Spring就是通过Cglib为DataService生成的动态代理。 JDK动态代理 JDK动态代理主要涉及到java.lang.reflect包中的Proxy和InvocationHandler两个类。InvocationHandler是一个接口，通过实现该接口定义横切逻辑，并通过反射机制调用目标类的代码，动态将横切逻辑和业务逻辑编织在一起。 Proxy利用InvocationHandler动态创建一个符合某一接口的实例，生成目标类的增强代理对象。 Cglib动态代理 CGLib全称为Code Generation Library，是一个强大的高性能，高质量的代码生成类库，可以在运行期扩展Java类与实现Java接口，CGLib封装了asm，可以再运行期动态生成新的class。和JDK动态代理相比较：JDK创建代理有一个限制，就是只能为接口创建代理实例，而对于没有通过接口定义业务方法的类，则可以通过CGLib创建动态代理，但是目标类不能为final，因为final修饰的类不允许继承。 End示例代码在GitHub，谢谢star。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>AOP</tag>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从源码开始重新认识ThreadLocal]]></title>
    <url>%2F2018%2F04%2F20%2F%E4%BB%8E%E6%BA%90%E7%A0%81%E5%BC%80%E5%A7%8B%E9%87%8D%E6%96%B0%E8%AE%A4%E8%AF%86ThreadLocal%2F</url>
    <content type="text"><![CDATA[从源码开始重新认识ThreadLocal 最近在巩固Java基础，发现很多平时在使用的东西，其实自己并不了解它的原理，在看了JDK1.8中ThreadLocal这个工具类的源码的同时，也翻看了很多大牛写的博客，总结下来，加深记忆。 简介从JDK1.2开始，Java就提供了ThreadLocal类。 所谓ThreadLocal，是Thread Local Variable（线程局部变量）的意思，ThreadLocal是java.lang包下提供的一个工具类，主要的作用是隔离线程资源，保证线程安全，通过ThreadLocal类，我们可以为每个线程创建一个独立的变量副本，从而避免并发访问时的线程安全问题。 基本方法ThreadLocal类似于HashMap，保存的是k:v型数据结构，但是他只能保存一个，各个线程的数据互不影响。 ThreadLocal只提供了一个空的构造函数。123456/** * Creates a thread local variable. * @see #withInitial(java.util.function.Supplier) */ public ThreadLocal() &#123; &#125; ThreadLocal中的get()方法，不用传入任何参数 1public T get(); ThreadLocal的set()方法，放入的是一个泛型参数 1public void set(T value); ThreadLocal的remove()方法 1public void remove(); 针对ThreadLocal的主要使用就是这三个方法，所以说ThreadLocal的使用其实并没有任何难度，不需要写任何同步代码就可以实现线程安全。 示例1234567891011121314151617181920212223242526272829303132333435363738394041424344public class ThreadLocalExample &#123; //定义一个String类型的ThreadLocal private static ThreadLocal&lt;String&gt; localVariable = new ThreadLocal&lt;&gt;(); //定义一个Integer类型的ThreadLocal private static ThreadLocal&lt;Integer&gt; localVariable1 = new ThreadLocal&lt;&gt;(); /** * 打印函数 * * @param */ private static void print() &#123; //打印当前线程本地内存中localVariable变量的值 System.out.println(Thread.currentThread().getName() + " String类型的ThreadLocal: " + localVariable.get()); System.out.println(Thread.currentThread().getName() + " Integer类型的ThreadLocal: " + localVariable1.get()); localVariable.remove(); &#125; public static void main(String[] args) &#123; new Thread(new ThreadLocalThread("线程1 data", 9090900), "线程1").start(); new Thread(new ThreadLocalThread("线程2 data", 9999999), "线程2").start(); &#125; static class ThreadLocalThread implements Runnable &#123; private String stringThreadLocal; private Integer integerThreadLocal; public ThreadLocalThread(String stringThreadLocal, Integer integerThreadLocal) &#123; this.stringThreadLocal = stringThreadLocal; this.integerThreadLocal = integerThreadLocal; &#125; @Override public void run() &#123; out.println("当前线程:" + Thread.currentThread().getName()); localVariable.set(stringThreadLocal); localVariable1.set(integerThreadLocal); //调用打印函数 print(); //打印本地变量 System.out.println(Thread.currentThread().getName() + " remove after: " + localVariable.get()); &#125; &#125;&#125; 输出结果 12345678当前线程:线程1线程1 String类型的ThreadLocal: 线程1 data线程1 Integer类型的ThreadLocal: 9090900线程1 remove after: null当前线程:线程2线程2 String类型的ThreadLocal: 线程2 data线程2 Integer类型的ThreadLocal: 9999999线程2 remove after: null 可以看出线程1和线程2的变量完全隔离开了。 从源码看原理那ThreadLocal是如何做到这些的呢，先来看看set方法的源码。 12345678910public void set(T value) &#123; //获取当前线程对象 Thread t = Thread.currentThread(); //获取ThreadLocalMap对象 ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 重点就在于这个ThreadLocalMap，ThreadLocal就是通过这玩意来实现线程隔离的。下面是getMap方法： 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 这里返回的是t对象也就是当前线程对象里面的threadLocals这个变量。我们再看看Thread源码：1234/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 看注释的意思是：threadLocals是用于修饰当前线程的ThreadLocal值，这个ThreadLocalMap变量由ThreadLocal来维护。 看到这里明白了，ThreadLocal之所以能够隔离线程资源，是因为每个线程的ThreadLocalMap都在当前线程对象里，其他线程根本无法访问到。 继续看set方法的源码，获取到ThreadLocalMap对象后，开始设置值。其中有两个操作：map.set(this, value)和createMap(t, value)，第一个是调用ThreadLocalMap的set方法，此处注意：传入的key是当前ThreadLocal对象，createMap方法是调用了ThreadLocalMap的构造方法，同样传入的key也是当前ThreadLocal对象，此处不贴代码了。 get()方法的源码12345678910111213141516public T get() &#123; //获取当前线程 Thread t = Thread.currentThread(); //获取ThreadLocalMap对象 ThreadLocalMap map = getMap(t); if (map != null) &#123; //拿到ThreadLocalMap中的Entry ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 从代码可以看出get方法要返回的值是ThreadLocalMap中的Entry对象的value值。 ThreadLocalMap从上面的分析中，已经认识到了ThreadLocalMap这个类的重要性，ThreadLocalMap是ThreadLocal的一个静态内部类，从命名来看，这也是一个map结构，没错，其实ThreadLocal中很多东西都和HashMap中的很像，接下来继续看ThreadLocalMap的源码。 调用ThreadLocalMap的构造方法，会初始化一个长度为16的Entry数组，每一个Entry对象保存的都是k-v键值对，key是ThreadLocal，调用ThreadLocal的set方法，相当于是把他自己当成key放进ThreadLocalMap中。 1234567891011121314151617181920/** * The table, resized as necessary. * table.length MUST always be a power of two. */private Entry[] table; /** * The initial capacity -- MUST be a power of two. */private static final int INITIAL_CAPACITY = 16;ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; //初始值16 table = new Entry[INITIAL_CAPACITY]; //计算下标，类似于HashMap计算bucket的位置，使用的是key的hashcode和length-1取模 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; //阈值默认为length的三分之二，从setThreshold()方法中可以得到 setThreshold(INITIAL_CAPACITY);&#125; 再看看Entry： 123456789static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; Entry继承了WeakReference这个类，并把key保存在了WeakReference中，这代表了Entry的key是一个弱引用，这会导致k也就是ThreadLocal对象在没有外部强引用指向它的时候，他会被gc强制回收。 ThreadLocalMap的set方法，ThreadLocal的set方法也是调用的这个方法。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Set the value associated with key. * * @param key the thread local object * @param value the value to be set */ private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; //同HashMap，计算元素位置 int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); //key相等，设置值 if (k == key) &#123; e.value = value; return; &#125; //遇到空槽，设置并替换过期的Entry if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash(); &#125; /** * Increment i modulo len. */ private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0); &#125; set的基本过程是： 根据key（ThreadLocal）的hashcode计算出Entry的位置，每个ThreadLocal对象都有一个hash值threadLocalHashCode，每初始化一个ThreadLocal对象，hash值就增加一个固定的大小0x61c88647。 然后和计算出的Entry的key进行比较，如果相等，那么就放入新值 如果计算出的Entry的k为空，说明已经被gc，就替换过期的Entry值 如果都没有满足，说明计算出的Entry的key和当前要设置的值没有任何关系，初始化一个新的Entry放入当前的位置 ThreadLocal的内存泄漏前面说过，Entry的key是个弱引用，如果被jvm的gc回收，那么就会出现一个问题，Entry的value在当前线程一直运行的情况下，Thread中持有ThreadLocalMap对象，相当于持有对Entry对象的强引用，如果线程不停止，Entry的value可能一直得不到回收，时间长了，就会发生内存泄漏。解决的办法是在使用了ThreadLocal的set方法后，显式的调用ThreadLocal的remove方法。 总结这是一张手画的ThreadLocal的基本原理图总结下来就是：每个Thread维护一个ThreadLocalMap映射表，这个map的key是ThreadLocal实例本身，value是真正需要存储的Object。ThreadLocal本身并不存储值，它只是作为一个key来让线程从map中获取value，虚线标识弱引用，表示ThreadLocalMap是使用ThreadLocal的弱引用作为key，弱引用在GC时会被回收。 源码看起来虽然很痛苦，但是却能学到很多东西，以前的自己很少去注意这些，只会使用，这样对于一个Java程序员修炼内功是极为不利的，如果有不对的地方，欢迎指出。 持续学习，夯实基础，共勉。 感谢以下的博客给了我很多帮助 占小狼，狼哥的博客给了我很多帮助 https://www.jianshu.com/p/377bb840802f @kiraSally https://www.zybuluo.com/kiraSally/note/854555]]></content>
      <categories>
        <category>Java Concurrency</category>
      </categories>
      <tags>
        <tag>并发</tag>
        <tag>JDK</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Dubbo2.5.10]]></title>
    <url>%2F2018%2F04%2F18%2FSpringBoot%E6%95%B4%E5%90%88Dubbo2-5-10%2F</url>
    <content type="text"><![CDATA[SpringBoot整合Dubbo2.5.10，使用官方最新spring-boot-starter开始Dubbo已经进入了Apache孵化器，并且发布了官方的spring-boot-starter0.1.0，用于简化dubbo应用的配置，主要包括了autoconfigure(自动装配)，externalized-configuration(外部化配置)，actuator(生产准备)等，可参考官方github dubbo-spring-boot-starter. 准备工作需要提前安装好JDK1.8，Maven，Zookeeper。 初始化Maven项目为了整个项目结构清晰，使用模块化的maven项目。pom文件如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://maven.apache.org/POM/4.0.0" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.8.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.boot.dubbo&lt;/groupId&gt; &lt;artifactId&gt;boot-dubbo&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;pom&lt;/packaging&gt; &lt;name&gt;boot-dubbo&lt;/name&gt; &lt;description&gt;Dubbo project for Spring Boot&lt;/description&gt; &lt;modules&gt; &lt;module&gt;dubbo-provider&lt;/module&gt; &lt;module&gt;dubbo-consumer&lt;/module&gt; &lt;module&gt;dubbo-api&lt;/module&gt; &lt;/modules&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;dubbo-spring-boot-starter.version&gt;0.1.0&lt;/dubbo-spring-boot-starter.version&gt; &lt;springboot.version&gt;1.5.8.RELEASE&lt;/springboot.version&gt; &lt;fastjson-version&gt;1.2.31&lt;/fastjson-version&gt; &lt;zk-client.version&gt;0.2&lt;/zk-client.version&gt; &lt;dockerfile-maven.version&gt;1.4.3&lt;/dockerfile-maven.version&gt; &lt;/properties&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;dubbo-spring-boot-starter.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;version&gt;$&#123;springboot.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;version&gt;$&#123;zk-client.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt;&lt;/project&gt; 主要分为三个模块，api，provider和consumer 创建生产者有了spring-boot-starter，dubbo的配置变得非常简单，再也不用像以前一样配置一大堆xml文件，只需要几个简单的配置，就可以做到开箱即用。 先配置生产者的pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://maven.apache.org/POM/4.0.0" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.boot.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-provider&lt;/artifactId&gt; &lt;version&gt;$&#123;parent.version&#125;&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;parent&gt; &lt;artifactId&gt;boot-dubbo&lt;/artifactId&gt; &lt;groupId&gt;org.boot.dubbo&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;name&gt;dubbo-provider&lt;/name&gt; &lt;description&gt;Dubbo project for Spring Boot:Provider&lt;/description&gt; &lt;dependencies&gt; &lt;!-- Spring Boot dependencies --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.boot.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-api&lt;/artifactId&gt; &lt;version&gt;$&#123;parent.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 接着使用properties进行SpringBoot和Dubbo的配置，配置如下： 123456789101112131415161718192021spring.application.name=springboot-dubbo-providerserver.port=9090#dubbo配置dubbo.application.id=springboot-dubbo-providerdubbo.application.name=springboot-dubbo-providerdubbo.application.owner=luoliang#协议配置dubbo.protocol.id=dubbodubbo.protocol.name=dubbo#把默认的20880端口换成12345dubbo.protocol.port=12345#服务注册配置dubbo.registry.id=my-registrydubbo.registry.address=zookeeper://localhost:2181#配置dubbo的包扫描，针对dubbo的@Service, @Reference注解dubbo.scan.base-packages=org.boot.dubbo.provider.service#dubbo健康监控endpoints.dubbo.enabled=truemanagement.health.dubbo.status.defaults=memorymanagement.health.dubbo.status.extras=load,threadpoolmanagement.port=9091 进行了上面两步之后，Dubbo已经集成好了，接下来就可以直接开始撸服务代码了，可以直接使用注解来暴露服务接口 先在api中写一个interface 123public interface HelloService &#123; String sayHello(String name);&#125; 实现接口，加上自己的业务逻辑 1234567891011@Service(version = "1.0.0", application = "$&#123;dubbo.application.id&#125;", protocol = "$&#123;dubbo.protocol.id&#125;", registry = "$&#123;dubbo.registry.id&#125;")public class HelloServiceImpl implements HelloService &#123; @Override public String sayHello(String name) &#123; return "Hello, " + name + " (from Spring Boot)"; &#125;&#125; 注意，这里的service注解是com.alibaba.dubbo.config.annotation.Service 创建消费者 配置消费者者的pom.xml 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://maven.apache.org/POM/4.0.0" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.boot.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-consumer&lt;/artifactId&gt; &lt;version&gt;$&#123;parent.version&#125;&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;parent&gt; &lt;artifactId&gt;boot-dubbo&lt;/artifactId&gt; &lt;groupId&gt;org.boot.dubbo&lt;/groupId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt; &lt;/parent&gt; &lt;name&gt;dubbo-consumer&lt;/name&gt; &lt;description&gt;Dubbo project for Spring Boot:Consumer&lt;/description&gt; &lt;dependencies&gt; &lt;!-- Spring Boot dependencies --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.boot&lt;/groupId&gt; &lt;artifactId&gt;dubbo-spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.101tec&lt;/groupId&gt; &lt;artifactId&gt;zkclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.boot.dubbo&lt;/groupId&gt; &lt;artifactId&gt;dubbo-api&lt;/artifactId&gt; &lt;version&gt;$&#123;parent.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; application.properties配置如下: 12345678910spring.application.name=springboot-dubbo-consumerserver.port=8081#dubbo配置dubbo.application.id=springboot-dubbo-consumerdubbo.application.name=springboot-dubbo-consumerdubbo.application.owner=luoliang#服务注册配置dubbo.registry.id=my-registrydubbo.registry.address=zookeeper://localhost:2181management.port=8082 编写service来消费dubbo的服务，主要代码如下： 1234567891011@Servicepublic class ConsumerServiceImpl implements ConsumerService &#123; @Reference(version = "1.0.0", application = "$&#123;dubbo.application.id&#125;") private HelloService helloService; @Override public String sayHello(String name) &#123; return helloService.sayHello(name); &#125;&#125; 在mvc的controller中注入此服务 1234567891011@RestController@RequestMapping("/user")public class DefaultController &#123; @Resource private ConsumerService consumerService; @RequestMapping("/sayHello") public String register(String name) &#123; return consumerService.sayHello(name); &#125;&#125; 到这里，整个项目基本结构已经搭建完成，consumer已经能够消费provider提供的服务。 现在来测试一下，分别启动provider和consumer，打开浏览器，输入http://localhost:8081/user/sayHello?name=dubbo 可以看到，返回的结果和预期一样，说明项目已经成功集成 需要源码请移步本人github，如果能顺手star就更好啦! boot-dubbo，下一篇博客接这篇博客，学习使用Docker容器化SpringBoot+Dubbo应用。 参考 https://github.com/apache/incubator-dubbo-spring-boot-project]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Dubbo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue+SpringBoot实现前后端分离的文件上传]]></title>
    <url>%2F2018%2F04%2F18%2FVue-SpringBoot%E5%AE%9E%E7%8E%B0%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E7%9A%84%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[Vue+SpringBoot实现前后端分离的文件上传这篇文章需要一定Vue和SpringBoot的知识，分为两个项目，一个是前端Vue项目，一个是后端SpringBoot项目。 后端项目搭建我使用的是SpringBoot1.5.10+JDK8+IDEA使用IDEA新建一个SpringBoot项目，一直点next即可 项目创建成功后，maven的pom配置如下1234567891011121314151617181920212223&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--加入web模块--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.39&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 接下来编写上传的API接口123456789101112131415161718192021222324252627282930313233@RestController@RequestMapping("/upload")@CrossOriginpublic class UploadController &#123; @Value("$&#123;prop.upload-folder&#125;") private String UPLOAD_FOLDER; private Logger logger = LoggerFactory.getLogger(UploadController.class); @PostMapping("/singlefile") public Object singleFileUpload(MultipartFile file) &#123; logger.debug("传入的文件参数：&#123;&#125;", JSON.toJSONString(file, true)); if (Objects.isNull(file) || file.isEmpty()) &#123; logger.error("文件为空"); return "文件为空，请重新上传"; &#125; try &#123; byte[] bytes = file.getBytes(); Path path = Paths.get(UPLOAD_FOLDER + file.getOriginalFilename()); //如果没有files文件夹，则创建 if (!Files.isWritable(path)) &#123; Files.createDirectories(Paths.get(UPLOAD_FOLDER)); &#125; //文件写入指定路径 Files.write(path, bytes); logger.debug("文件写入成功..."); return "文件上传成功"; &#125; catch (IOException e) &#123; e.printStackTrace(); return "后端异常..."; &#125; &#125;&#125; CrossOrigin注解：解决跨域问题，因为前后端完全分离，跨域问题在所难免，加上这个注解会让Controller支持跨域，如果去掉这个注解，前端Ajax请求不会到后端。这只是跨域的一种解决方法，还有其他解决方法这篇文章先不涉及。 MultipartFile：SpringMVC的multipartFile对象，用于接收前端请求传入的FormData。 PostMapping是Spring4.3以后引入的新注解，是为了简化HTTP方法的映射，相当于我们常用的@RequestMapping(value = “/xx”, method = RequestMethod.POST). 后端至此已经做完了，很简单。前端项目搭建我使用的是Node8+Webpack3+Vue2 本地需要安装node环境，且安装Vue-cli，使用Vue-cli生成一个Vue项目。 项目创建成功之后，用WebStorm打开，就可以写一个简单的上传例子了，主要代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;template&gt; &lt;div class="hello"&gt; &lt;h1&gt;&#123;&#123; msg &#125;&#125;&lt;/h1&gt; &lt;form&gt; &lt;input type="file" @change="getFile($event)"&gt; &lt;button class="button button-primary button-pill button-small" @click="submit($event)"&gt;提交&lt;/button&gt; &lt;/form&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt; import axios from 'axios'; export default &#123; name: 'HelloWorld', data() &#123; return &#123; msg: 'Welcome to Your Vue.js App', file: '' &#125; &#125;, methods: &#123; getFile: function (event) &#123; this.file = event.target.files[0]; console.log(this.file); &#125;, submit: function (event) &#123; //阻止元素发生默认的行为 event.preventDefault(); let formData = new FormData(); formData.append("file", this.file); axios.post('http://localhost:8082/upload/singlefile', formData) .then(function (response) &#123; alert(response.data); console.log(response); window.location.reload(); &#125;) .catch(function (error) &#123; alert("上传失败"); console.log(error); window.location.reload(); &#125;); &#125; &#125; &#125;&lt;/script&gt; 使用Axios向后端发送Ajax请求，使用H5的FormData对象封装图片数据 测试启动服务端，直接运行BootApplication类的main方法，端口8082 启动前端，端口默认8080，cd到前端目录下，分别执行： npm install npm run dev 启动成功后访问localhost:8080 选择一张图片上传，可以看到，上传成功之后，后端指定目录下也有了图片文件 总结，到这里，一个前后端分离的上传例子就做完了，如有不对的，请指正，大家共同进步。最后，附上源码，欢迎star：boot-upload。]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>Vue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot整合Elastic-Job-lite，实现动态创建定时任务，任务持久化]]></title>
    <url>%2F2018%2F04%2F17%2FSpringBoot-ElasticJob%2F</url>
    <content type="text"><![CDATA[SpringBoot整合Elastic-Job-lite，实现动态创建定时任务，任务持久化Elastic-Job是当当开源的一个分布式调度解决方案，由两个相互独立的子项目Elastic-Job-Lite和Elastic-Job-Cloud组成。 Elastic-Job-Lite定位为轻量级无中心化解决方案，使用jar包的形式提供分布式任务的协调服务；Elastic-Job-Cloud采用自研Mesos Framework的解决方案，额外提供资源治理、应用分发以及进程隔离等功能。 这里以Elastic-Job-lite为例，跟SpringBoot进行整合，当当的官方文档中并没有对SpringBoot集成作说明，所有的配置都是基于文档中的xml的配置修改出来的。 起步准备好一个SpringBoot的项目，pom.xml中引入Elastic-job，mysql，jpa等依赖1234567891011121314151617181920212223242526272829303132333435363738&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.dangdang&lt;/groupId&gt; &lt;artifactId&gt;elastic-job-lite-spring&lt;/artifactId&gt; &lt;version&gt;2.1.5&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 配置使用yaml进行相关属性的配置，主要配置的是数据库连接池，jpa 1234567891011121314151617elasticjob: serverlists: 172.31.31.48:2181 namespace: boot-job spring: datasource: url: jdbc:mysql://localhost:3306/test?characterEncoding=utf-8&amp;verifyServerCertificate=false&amp;useSSL=false&amp;requireSSL=false driver-class-name: com.mysql.jdbc.Driver username: root password: root type: com.zaxxer.hikari.HikariDataSource # 自动创建更新验证数据库结构 jpa: hibernate: ddl-auto: update show-sql: true database: mysql elastic-job相关的配置使用java配置实现，代替官方文档的xml配置12345678910111213141516171819202122232425262728293031323334@Configuration@Data@ConfigurationProperties(prefix = "elasticjob")public class ElasticJobConfig &#123; private String serverlists; private String namespace; @Resource private HikariDataSource dataSource; @Bean public ZookeeperConfiguration zkConfig() &#123; return new ZookeeperConfiguration(serverlists, namespace); &#125; @Bean(initMethod = "init") public ZookeeperRegistryCenter regCenter(ZookeeperConfiguration config) &#123; return new ZookeeperRegistryCenter(config); &#125; /** * 将作业运行的痕迹进行持久化到DB * * @return */ @Bean public JobEventConfiguration jobEventConfiguration() &#123; return new JobEventRdbConfiguration(dataSource); &#125; @Bean public ElasticJobListener elasticJobListener() &#123; return new ElasticJobListener(100, 100); &#125;&#125; 所有相关的配置到这里就已经OK了，接下来开始具体的编码实现 定时任务实现先实现一个自己的任务类，需要实现elastic-job提供的SimpleJob接口，实现它的execute(ShardingContext shardingContext)方法123456789@Slf4jpublic class MyElasticJob implements SimpleJob &#123; @Override public void execute(ShardingContext shardingContext) &#123; //打印出任务相关信息，JobParameter用于传递任务的ID log.info("任务名：&#123;&#125;, 片数：&#123;&#125;, id=&#123;&#125;", shardingContext.getJobName(), shardingContext.getShardingTotalCount(), shardingContext.getJobParameter()); &#125;&#125; 接下来实现一个分布式的任务监听器，如果任务有分片，分布式监听器会在总的任务开始前执行一次，结束时执行一次。监听器在之前的ElasticJobConfig已经注册到了Spring容器之中。1234567891011121314151617181920public class ElasticJobListener extends AbstractDistributeOnceElasticJobListener &#123; @Resource private TaskRepository taskRepository; public ElasticJobListener(long startedTimeoutMilliseconds, long completedTimeoutMilliseconds) &#123; super(startedTimeoutMilliseconds, completedTimeoutMilliseconds); &#125; @Override public void doBeforeJobExecutedAtLastStarted(ShardingContexts shardingContexts) &#123; &#125; @Override public void doAfterJobExecutedAtLastCompleted(ShardingContexts shardingContexts) &#123; //任务执行完成后更新状态为已执行 JobTask jobTask = taskRepository.findOne(Long.valueOf(shardingContexts.getJobParameter())); jobTask.setStatus(1); taskRepository.save(jobTask); &#125;&#125; 实现一个ElasticJobHandler，用于向Elastic-job中添加指定的作业配置，作业配置分为3级，分别是JobCoreConfiguration，JobTypeConfiguration和LiteJobConfiguration。LiteJobConfiguration使用JobTypeConfiguration，JobTypeConfiguration使用JobCoreConfiguration，层层嵌套。12345678910111213141516171819202122232425262728293031323334353637383940@Componentpublic class ElasticJobHandler &#123; @Resource private ZookeeperRegistryCenter registryCenter; @Resource private JobEventConfiguration jobEventConfiguration; @Resource private ElasticJobListener elasticJobListener; /** * @param jobName * @param jobClass * @param shardingTotalCount * @param cron * @param id 数据ID * @return */ private static LiteJobConfiguration.Builder simpleJobConfigBuilder(String jobName, Class&lt;? extends SimpleJob&gt; jobClass, int shardingTotalCount, String cron, String id) &#123; return LiteJobConfiguration.newBuilder(new SimpleJobConfiguration( JobCoreConfiguration.newBuilder(jobName, cron, shardingTotalCount).jobParameter(id).build(), jobClass.getCanonicalName())); &#125; /** * 添加一个定时任务 * * @param jobName 任务名 * @param cron 表达式 * @param shardingTotalCount 分片数 */ public void addJob(String jobName, String cron, Integer shardingTotalCount, String id) &#123; LiteJobConfiguration jobConfig = simpleJobConfigBuilder(jobName, MyElasticJob.class, shardingTotalCount, cron, id) .overwrite(true).build(); new SpringJobScheduler(new MyElasticJob(), registryCenter, jobConfig, jobEventConfiguration, elasticJobListener).init(); &#125;&#125; 到这里，elastic-job的注册中心，数据源相关配置，以及动态添加的逻辑已经做完了，接下来在service中调用上面写好的方法，验证功能是否正常。 编写一个ElasticJobService类，扫描数据库中状态为0的任务，并且把这些任务添加到Elastic-job中，这里的相关数据库操作使用了spring-data-jpa，dao层相关代码就不贴了，可以在源码中查看。1234567891011121314151617181920212223242526272829@Servicepublic class ElasticJobService &#123; @Resource private ElasticJobHandler jobHandler; @Resource private TaskRepository taskRepository; /** * 扫描db，并添加任务 */ public void scanAddJob() &#123; Specification query = (Specification&lt;JobTask&gt;) (root, criteriaQuery, criteriaBuilder) -&gt; criteriaBuilder .and(criteriaBuilder.equal(root.get("status"), 0)); List&lt;JobTask&gt; jobTasks = taskRepository.findAll(query); jobTasks.forEach(jobTask -&gt; &#123; Long current = System.currentTimeMillis(); String jobName = "job" + jobTask.getSendTime(); String cron; //说明消费未发送，但是已经过了消息的发送时间，调整时间继续执行任务 if (jobTask.getSendTime() &lt; current) &#123; //设置为一分钟之后执行，把Date转换为cron表达式 cron = CronUtils.getCron(new Date(current + 60000)); &#125; else &#123; cron = CronUtils.getCron(new Date(jobTask.getSendTime())); &#125; jobHandler.addJob(jobName, cron, 1, String.valueOf(jobTask.getId())); &#125;); &#125;&#125; 在Junit中添加几条测试数据1234567891011121314151617181920212223@RunWith(SpringJUnit4ClassRunner.class)@SpringBootTestpublic class JobTaskTest &#123; @Resource private TaskRepository taskRepository; @Test public void add() &#123; //生成几个任务，第一任务在三分钟之后 Long unixTime = System.currentTimeMillis() + 60000; JobTask task = new JobTask("test-msg-1", 0, unixTime); taskRepository.save(task); unixTime += 60000; task = new JobTask("test-msg-2", 0, unixTime); taskRepository.save(task); unixTime += 60000; task = new JobTask("test-msg-3", 0, unixTime); taskRepository.save(task); unixTime += 60000; task = new JobTask("test-msg-4", 0, unixTime); taskRepository.save(task); &#125;&#125; 此时，数据库中多了四条状态为0的数据 最后，就可以开始验证整个流程了，代码如下1234567891011121314@SpringBootApplicationpublic class ElasticJobApplication implements CommandLineRunner &#123; @Resource private ElasticJobService elasticJobService; public static void main(String[] args) &#123; SpringApplication.run(ElasticJobApplication.class, args); &#125; @Override public void run(String... strings) throws Exception &#123; elasticJobService.scanAddJob(); &#125;&#125; 可以看到，在启动过程中，多个任务被加入到了Elastic-job中，并且一小段时间之后，任务一次执行，执行成功之后，因为我们配置了监听器，会打印数据库的更新SQL，当任务执行完成，再查看数据库，发现状态也更改成功。数据库中同时也会多出两张表JOB_EXECUTION_LOG，JOB_STATUS_TRACE_LOG，这是我们之前配置的JobEventConfiguration，通过数据源持久化了作业配置的相关数据，这两张表的数据可以供Elastic-job提供的运维平台使用，具体请查看官方文档。 总结至此，整个流程就已经走完了，整个demo中主要用到了Elastic-job和spring-data-jpa相关的技术，作为demo，肯定会有一些缺陷，没考虑到的地方，可以根据自己的业务场景进行改进。 最后，附上github源码，欢迎star，一起交流。上面涉及到的数据库，请自行创建，表会自动生成。boot-elasticjob]]></content>
      <categories>
        <category>SpringBoot</category>
      </categories>
      <tags>
        <tag>SpringBoot</tag>
        <tag>ElasticJob</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F04%2F17%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Hello World欢迎来到我的个人博客，今天终于开通了我的个人博客，以后将在这里分享我的生活，学习经历。]]></content>
  </entry>
</search>
